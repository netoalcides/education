{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemplo Árvore Regressão com PCA\n",
    "\n",
    "Neste exemplo será utilizado os dados da pesquisa sobre *Nerdy Personality Attributes Scale*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregar pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(magrittr)\n",
    "library(psych)\n",
    "library(plotly)\n",
    "library(rpart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções gerais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse <- function( real, prediction ){ sqrt( mean( (real - prediction)^2 ) ) }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregar dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load( '/home/vm-data-science/dados/dados_nerd_nomissings.RData' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_nerd_train %>% \n",
    "    head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_nerd_test %>% \n",
    "    head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise exploratória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# count em todas as colunas\n",
    "dados_nerd_train %>% \n",
    "  map( ~count(data.frame(x=.x), x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograma\n",
    "dados_nerd_train %>% \n",
    "  ggplot( aes( x = nerdy ) ) +\n",
    "  geom_histogram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outliers\n",
    "dados_nerd_train %>% \n",
    "  dplyr::select( contains('Q') ) %>% \n",
    "  gather( key = variaveis, value = notas ) %>% \n",
    "  plot_ly( x = ~variaveis,\n",
    "           y = ~notas,\n",
    "           type = 'box' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combinação de técnicas supervisionadas com não supervisionadas\n",
    "\n",
    "1 - Aplicamos o algoritmo não supervisionado\n",
    "\n",
    "2 - Geramos os novos atributos no banco de dados\n",
    "\n",
    "3 - Aplicamos o algoritmo supervisionado com os atributos obtidos pelo não supervisionado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Aplicamos o PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Verificamos a correlação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlacao <- dados_nerd_train %>% \n",
    "  dplyr::select( contains('Q') ) %>% \n",
    "  cor() %>% \n",
    "  round(., 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ly( z = correlacao,\n",
    "         x = colnames(correlacao),\n",
    "         y = colnames(correlacao), \n",
    "         colorscale = \"Greys\", \n",
    "         type = \"heatmap\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Aplicamos o PCA ( nfactors = 26 porque temos 26 questões)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_model <- principal(dados_nerd_train %>% \n",
    "                         dplyr::select( contains('Q') ), \n",
    "                       nfactors = 26, \n",
    "                       rotate = \"none\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Verificamos o *screeplot*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_model$values %>% \n",
    "  as_data_frame %>% \n",
    "  rename( autovalor = value ) %>% \n",
    "  mutate( dimensao = 1:26 ) %>% \n",
    "  plot_ly(x = ~dimensao,\n",
    "          y = ~autovalor,\n",
    "          type = 'scatter',\n",
    "          mode = 'lines+markers',\n",
    "          marker = list(size = 10, color = 'red') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Verificamos a variância explicada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_model$Vaccounted %>% \n",
    "  as.data.frame() %>% \n",
    "  rownames_to_column( var = 'medidas' ) %>% \n",
    "  gather( key = PC, value = valores, -medidas ) %>% \n",
    "  spread( key = medidas, value = valores ) %>% \n",
    "  arrange( desc(`SS loadings`) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pela observação do *screeplot* percebe-se que a partir do componente 7 não há grande variação. Porém, caso 7 componentes sejam escolhidos somente 58% da informação é explicada por estes dados.\n",
    "\n",
    "\n",
    "- Diante disto, buscamos adicionar os componentes 8 a 11 para que 70% da informação seja explicada pelos componentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Geramos os novos atributos no banco de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos os componentes num objeto\n",
    "scores_pca <- pca_model$scores[, 1:11] %>% \n",
    "  as_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionamos os componentes no banco\n",
    "dados_nerd_train_modelo <- dados_nerd_train %>% \n",
    "  bind_cols(., scores_pca )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_nerd_train_modelo %>% \n",
    "    head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Aplicamos o modelo de árvore de decisão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Alguns ajustes importantes no banco de dados no R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_nerd_train_modelo %<>% \n",
    "  mutate( gender = as.factor(gender),\n",
    "          education = as.factor(education),\n",
    "          married = as.factor(married),\n",
    "          ASD = as.factor(ASD) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dividir a amostra de treinamento em: treino/validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treino\n",
    "set.seed(543)\n",
    "dados_nerd_train_modelo_train <- dados_nerd_train_modelo %>% \n",
    "  sample_frac(., 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validacao\n",
    "dados_nerd_train_modelo_valid <- setdiff( dados_nerd_train_modelo, dados_nerd_train_modelo_train )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ajustes de poda para vários modelos de árvore em sequência\n",
    "\n",
    "Usamos a amostra de treino para ajustar o modelo e a amostra de validação para selecionar os melhores e realizar o teste final na amostra de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteracoes <- 150 # numero de iteracoes para tunning\n",
    "s_seeds <- sample(1000000:9999999, iteracoes) # sementes aleatorias\n",
    "dados_amostra_avaliacao_questoes <- NULL\n",
    "dados_amostra_avaliacao_pca <- NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ( iter in 1:iteracoes ){\n",
    "  \n",
    "  set.seed( s_seeds[iter] )\n",
    "  minsplit_ <- sample(10:30, 1)\n",
    "  cp_ <- runif(1, 0.001, 0.1)\n",
    "  maxcompete_ <- sample(3:30, 1)\n",
    "  maxdepth_ <- sample(10:50, 1)\n",
    "  \n",
    "  modelo_arvore_questoes <- rpart( formula = nerdy ~ ., \n",
    "                          data = dados_nerd_train_modelo_train %>% \n",
    "                            dplyr::select( nerdy, contains('Q') ),\n",
    "                          control = list( minsplit = minsplit_,\n",
    "                                          cp = cp_,\n",
    "                                          maxcompete = maxcompete_,\n",
    "                                          maxdepth = maxdepth_ ) )\n",
    "  \n",
    "  modelo_arvore_pca <- rpart( formula = nerdy ~ ., \n",
    "                                   data = dados_nerd_train_modelo_train %>% \n",
    "                                     dplyr::select( nerdy, contains('PC') ),\n",
    "                                   control = list( minsplit = minsplit_,\n",
    "                                                   cp = cp_,\n",
    "                                                   maxcompete = maxcompete_,\n",
    "                                                   maxdepth = maxdepth_ ) )\n",
    "  \n",
    "  pred_tree_questoes <- predict( modelo_arvore_questoes, dados_nerd_train_modelo_valid )\n",
    "  pred_tree_pca <- predict( modelo_arvore_pca, dados_nerd_train_modelo_valid )\n",
    "  \n",
    "  erro_questoes <- rmse( dados_nerd_train_modelo_valid$nerdy, pred_tree_questoes )\n",
    "  erro_pca <- rmse( dados_nerd_train_modelo_valid$nerdy, pred_tree_pca )\n",
    "  \n",
    "  aval_questoes <- data_frame( seed = s_seeds[iter],\n",
    "                      minsplit_ = minsplit_,\n",
    "                      cp_ = cp_,\n",
    "                      maxcompete_ = maxcompete_,\n",
    "                      maxdepth_ = maxdepth_,\n",
    "                      erro = erro_questoes )\n",
    "  \n",
    "  aval_pca <- data_frame( seed = s_seeds[iter],\n",
    "                               minsplit_ = minsplit_,\n",
    "                               cp_ = cp_,\n",
    "                               maxcompete_ = maxcompete_,\n",
    "                               maxdepth_ = maxdepth_,\n",
    "                               erro = erro_pca )\n",
    "  \n",
    "  dados_amostra_avaliacao_questoes <- bind_rows( dados_amostra_avaliacao_questoes, aval_questoes )\n",
    "  dados_amostra_avaliacao_pca <- bind_rows( dados_amostra_avaliacao_pca, aval_pca )\n",
    "  \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Salvamos os melhores modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bests_questoes <- dados_amostra_avaliacao_questoes %>% \n",
    "  arrange( erro ) %>% \n",
    "  head(1)\n",
    "\n",
    "bests_pca <- dados_amostra_avaliacao_pca %>% \n",
    "  arrange( erro ) %>% \n",
    "  head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bests_questoes\n",
    "bests_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Retreina os melhores modelos e guarda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_arvore_1 <- rpart( formula = nerdy ~ ., \n",
    "                        data = dados_nerd_train_modelo_train %>% \n",
    "                          dplyr::select( nerdy, contains('Q') ),\n",
    "                        control = list( minsplit = bests_questoes$minsplit_[1],\n",
    "                                        cp = bests_questoes$cp_[1],\n",
    "                                        maxcompete = bests_questoes$maxcompete_[1],\n",
    "                                        maxdepth = bests_questoes$maxdepth_[1] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_arvore_2 <- rpart( formula = nerdy ~ ., \n",
    "                          data = dados_nerd_train_modelo_train %>% \n",
    "                            dplyr::select( nerdy, contains('PC') ),\n",
    "                          control = list( minsplit = bests_pca$minsplit_[1],\n",
    "                                          cp = bests_pca$cp_[1],\n",
    "                                          maxcompete = bests_pca$maxcompete_[1],\n",
    "                                          maxdepth = bests_pca$maxdepth_[1] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação dos modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Criamos os PC`s usando os dados da amostra de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_teste <- predict( pca_model, \n",
    "         dados_nerd_test %>% \n",
    "           dplyr::select( contains('Q') ) ) %>% \n",
    "  tbl_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adicionamos os PC`s na amostra de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_nerd_test_modelo <- dados_nerd_test %>% \n",
    "  bind_cols(., scores_teste[, 1:11] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_nerd_test_modelo %>% \n",
    "    head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Geramos as previsoes para avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amostra_avaliacao <- dados_nerd_test_modelo %>% \n",
    "  mutate( pred_modelo_1 = predict( modelo_arvore_1, . ),\n",
    "          pred_modelo_2 = predict( modelo_arvore_2, . ) ) %>% \n",
    "  dplyr::select(nerdy, pred_modelo_1, pred_modelo_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amostra_avaliacao %>% \n",
    "    head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comparamos os modelos pelo RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amostra_avaliacao %>% \n",
    "  summarise( Modelo_1_questoes = rmse(nerdy, pred_modelo_1),\n",
    "             Modelo_2_pca = rmse(nerdy, pred_modelo_2) ) %>% \n",
    "  gather( key = modelos, value = rmse ) %>% \n",
    "  arrange( rmse )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Apesar que o melhor modelo apresentou menor erro, os modelos utilizando número menor de questões apresentaram resultados similares."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
