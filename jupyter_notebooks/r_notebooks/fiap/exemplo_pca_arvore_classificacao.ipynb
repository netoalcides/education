{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemplo Árvore de classificação com PCA\n",
    "\n",
    "Neste exemplo será utilizado os dados da pesquisa sobre *Nerdy Personality Attributes Scale*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregar pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(magrittr)\n",
    "library(psych)\n",
    "library(plotly)\n",
    "library(rpart)\n",
    "library(caret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregar dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load( '/home/vm-data-science/dados/dados_nerd_nomissings.RData' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_nerd_train %>% \n",
    "    head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dados_nerd_test %>% \n",
    "    head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação da classificação: 1 - nerd, 0 - não nerd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_nerd_train %<>% \n",
    "  mutate( nerdy_classification = ifelse( nerdy > 5, 1, 0) )\n",
    " \n",
    "dados_nerd_test %<>% \n",
    "  mutate( nerdy_classification = ifelse( nerdy > 5, 1, 0) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise exploratória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# count em todas as colunas\n",
    "dados_nerd_train %>% \n",
    "  map( ~count(data.frame(x=.x), x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outliers\n",
    "dados_nerd_train %>% \n",
    "  dplyr::select( contains('Q') ) %>% \n",
    "  gather( key = variaveis, value = notas ) %>% \n",
    "  plot_ly( x = ~variaveis,\n",
    "           y = ~notas,\n",
    "           type = 'box' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combinação de técnicas supervisionadas com não supervisionadas\n",
    "\n",
    "1 - Aplicamos o algoritmo não supervisionado\n",
    "\n",
    "2 - Geramos os novos atributos no banco de dados\n",
    "\n",
    "3 - Aplicamos o algoritmo supervisionado com os atributos obtidos pelo não supervisionado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Aplicamos o PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Verificamos a correlação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlacao <- dados_nerd_train %>% \n",
    "  dplyr::select( contains('Q') ) %>% \n",
    "  cor() %>% \n",
    "  round(., 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ly( z = correlacao,\n",
    "         x = colnames(correlacao),\n",
    "         y = colnames(correlacao), \n",
    "         colorscale = \"Greys\", \n",
    "         type = \"heatmap\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Aplicamos o PCA ( nfactors = 26 porque temos 26 questões)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_model <- principal(dados_nerd_train %>% \n",
    "                         dplyr::select( contains('Q') ), \n",
    "                       nfactors = 26, \n",
    "                       rotate = \"none\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Verificamos o *screeplot*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_model$values %>% \n",
    "  as_data_frame %>% \n",
    "  rename( autovalor = value ) %>% \n",
    "  mutate( dimensao = 1:26 ) %>% \n",
    "  plot_ly(x = ~dimensao,\n",
    "          y = ~autovalor,\n",
    "          type = 'scatter',\n",
    "          mode = 'lines+markers',\n",
    "          marker = list(size = 10, color = 'red') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Verificamos a variância explicada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_model$Vaccounted %>% \n",
    "  as.data.frame() %>% \n",
    "  rownames_to_column( var = 'medidas' ) %>% \n",
    "  gather( key = PC, value = valores, -medidas ) %>% \n",
    "  spread( key = medidas, value = valores ) %>% \n",
    "  arrange( desc(`SS loadings`) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pela observação do *screeplot* percebe-se que a partir do componente 7 não há grande variação. Porém, caso 7 componentes sejam escolhidos somente 58% da informação é explicada por estes dados.\n",
    "\n",
    "\n",
    "- Diante disto, buscamos adicionar os componentes 8 a 11 para que 70% da informação seja explicada pelos componentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Geramos os novos atributos no banco de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos os componentes num objeto\n",
    "scores_pca <- pca_model$scores[, 1:11] %>% \n",
    "  as_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionamos os componentes no banco\n",
    "dados_nerd_train_modelo <- dados_nerd_train %>% \n",
    "  bind_cols(., scores_pca )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_nerd_train_modelo %>% \n",
    "    head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Aplicamos o modelo de árvore de decisão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Alguns ajustes importantes no banco de dados no R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_nerd_train_modelo %<>% \n",
    "  mutate( gender = as.factor(gender),\n",
    "          education = as.factor(education),\n",
    "          married = as.factor(married),\n",
    "          ASD = as.factor(ASD),\n",
    "          nerdy_classification = as.factor(nerdy_classification) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dividir a amostra de treinamento em: treino/validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treino\n",
    "set.seed(543)\n",
    "dados_nerd_train_modelo_train <- dados_nerd_train_modelo %>% \n",
    "  sample_frac(., 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validacao\n",
    "dados_nerd_train_modelo_valid <- setdiff( dados_nerd_train_modelo, dados_nerd_train_modelo_train )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ajustes de poda para vários modelos de árvore em sequência\n",
    "\n",
    "Usamos a amostra de treino para ajustar o modelo e a amostra de validação para selecionar os melhores e realizar o teste final na amostra de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteracoes <- 150 # numero de iteracoes para tunning\n",
    "s_seeds <- sample(1000000:9999999, iteracoes) # sementes aleatorias\n",
    "dados_amostra_avaliacao_questoes <- NULL\n",
    "dados_amostra_avaliacao_pca <- NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ( iter in 1:iteracoes ){\n",
    "  \n",
    "  set.seed( s_seeds[iter] )\n",
    "  minsplit_ <- sample(5:30, 1)\n",
    "  cp_ <- runif(1, 0.001, 0.1)\n",
    "  maxcompete_ <- sample(2:30, 1)\n",
    "  maxdepth_ <- sample(10:50, 1)\n",
    "  \n",
    "  modelo_arvore_questoes <- rpart( formula = nerdy_classification ~ .,\n",
    "                                   method = \"class\",\n",
    "                                   data = dados_nerd_train_modelo_train %>% \n",
    "                                     dplyr::select( nerdy_classification, contains('Q') ),\n",
    "                                   control = list( minsplit = minsplit_,\n",
    "                                                   cp = cp_,\n",
    "                                                   maxcompete = maxcompete_,\n",
    "                                                   maxdepth = maxdepth_,\n",
    "                                                   xval = 0 ) )\n",
    "  \n",
    "  modelo_arvore_pca <- rpart( formula = nerdy_classification ~ .,\n",
    "                              method = \"class\",\n",
    "                              data = dados_nerd_train_modelo_train %>% \n",
    "                                dplyr::select( nerdy_classification, contains('PC') ),\n",
    "                              control = list( minsplit = minsplit_,\n",
    "                                              cp = cp_,\n",
    "                                              maxcompete = maxcompete_,\n",
    "                                              maxdepth = maxdepth_,\n",
    "                                              xval = 0 ) )\n",
    "  \n",
    "  pred_tree_questoes <- predict( modelo_arvore_questoes, dados_nerd_train_modelo_valid, type = 'class' )\n",
    "  pred_tree_pca <- predict( modelo_arvore_pca, dados_nerd_train_modelo_valid, type = 'class' )\n",
    "  \n",
    "  \n",
    "  acc_questoes <- confusionMatrix( pred_tree_questoes,\n",
    "                   dados_nerd_train_modelo_valid$nerdy_classification,\n",
    "                   positive = '1' )$overall[1]\n",
    "  \n",
    "  acc_pca <- confusionMatrix( pred_tree_pca,\n",
    "                   dados_nerd_train_modelo_valid$nerdy_classification,\n",
    "                   positive = '1' )$overall[1]\n",
    "\n",
    "  \n",
    "  aval_questoes <- data_frame( seed = s_seeds[iter],\n",
    "                               minsplit_ = minsplit_,\n",
    "                               cp_ = cp_,\n",
    "                               maxcompete_ = maxcompete_,\n",
    "                               maxdepth_ = maxdepth_,\n",
    "                               acuracia = acc_questoes )\n",
    "  \n",
    "  aval_pca <- data_frame( seed = s_seeds[iter],\n",
    "                          minsplit_ = minsplit_,\n",
    "                          cp_ = cp_,\n",
    "                          maxcompete_ = maxcompete_,\n",
    "                          maxdepth_ = maxdepth_,\n",
    "                          acuracia = acc_pca )\n",
    "  \n",
    "  dados_amostra_avaliacao_questoes <- bind_rows( dados_amostra_avaliacao_questoes, aval_questoes )\n",
    "  dados_amostra_avaliacao_pca <- bind_rows( dados_amostra_avaliacao_pca, aval_pca )\n",
    "  \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Salvamos os melhores modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bests_questoes <- dados_amostra_avaliacao_questoes %>% \n",
    "  arrange( acuracia ) %>% \n",
    "  head(1)\n",
    "\n",
    "bests_pca <- dados_amostra_avaliacao_pca %>% \n",
    "  arrange( acuracia ) %>% \n",
    "  head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bests_questoes\n",
    "bests_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Retreina os melhores modelos e guarda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_arvore_1 <- rpart( formula = nerdy_classification ~ ., \n",
    "                          data = dados_nerd_train_modelo_train %>% \n",
    "                            dplyr::select( nerdy_classification, contains('Q') ),\n",
    "                          control = list( minsplit = bests_questoes$minsplit_[1],\n",
    "                                          cp = bests_questoes$cp_[1],\n",
    "                                          maxcompete = bests_questoes$maxcompete_[1],\n",
    "                                          maxdepth = bests_questoes$maxdepth_[1],\n",
    "                                          xval = 0 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_arvore_2 <- rpart( formula = nerdy_classification ~ ., \n",
    "                          data = dados_nerd_train_modelo_train %>% \n",
    "                            dplyr::select( nerdy_classification, contains('PC') ),\n",
    "                          control = list( minsplit = bests_pca$minsplit_[1],\n",
    "                                          cp = bests_pca$cp_[1],\n",
    "                                          maxcompete = bests_pca$maxcompete_[1],\n",
    "                                          maxdepth = bests_pca$maxdepth_[1],\n",
    "                                          xval = 0 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação dos modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Criamos os PC`s usando os dados da amostra de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_teste <- predict( pca_model, \n",
    "         dados_nerd_test %>% \n",
    "           dplyr::select( contains('Q') ) ) %>% \n",
    "  tbl_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adicionamos os PC`s na amostra de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_nerd_test_modelo <- dados_nerd_test %>% \n",
    "  mutate( gender = as.factor(gender),\n",
    "          education = as.factor(education),\n",
    "          married = as.factor(married),\n",
    "          ASD = as.factor(ASD),\n",
    "          nerdy_classification = as.factor(nerdy_classification) ) %>% \n",
    "  bind_cols(., scores_teste[, 1:11] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_nerd_test_modelo %>% \n",
    "    head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Geramos as previsoes para avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in dados_nerd_test_modelo %>% mutate(pred_nerdy_arvore_questoes = as.factor(predict(modelo_arvore_1, : could not find function \"%>%\"\n",
     "output_type": "error",
     "traceback": [
      "Error in dados_nerd_test_modelo %>% mutate(pred_nerdy_arvore_questoes = as.factor(predict(modelo_arvore_1, : could not find function \"%>%\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "dados_avaliacao <- dados_nerd_test_modelo %>% \n",
    "  mutate( pred_nerdy_arvore_questoes = predict( modelo_arvore_1, ., type = 'class' ),\n",
    "          pred_nerdy_arvore_pca = predict( modelo_arvore_2, ., type = 'class' ) ) %>% \n",
    "  dplyr::select( nerdy_classification, pred_nerdy_arvore_questoes, pred_nerdy_arvore_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_avaliacao %>% \n",
    "    head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comparamos os modelos pela matriz de confusão e acurácia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 1: somente as 26 questões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusionMatrix( dados_avaliacao$pred_nerdy_arvore_questoes,\n",
    "                 dados_avaliacao$nerdy_classification,\n",
    "                 positive = '1' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 2: somente os PC`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusionMatrix( dados_avaliacao$pred_nerdy_arvore_pca,\n",
    "                 dados_avaliacao$nerdy_classification,\n",
    "                 positive = '1' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
