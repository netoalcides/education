{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemplo Análise de textos - movie review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O arquivo *movie_review* armazena uma coleção de avaliações com os respectivos sentimentos, sendo 1 - positivo e 0 - negativo.\n",
    "\n",
    "O arquivo foi baseado neste dataset: http://ai.stanford.edu/~amaas/data/sentiment/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregar pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(magrittr)\n",
    "library(tm)\n",
    "library(SnowballC)\n",
    "library(wordcloud)\n",
    "library(text2vec)\n",
    "library(glmnet)\n",
    "library(caret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregar dados (*Corpus*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data(\"movie_review\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_review %>% \n",
    "    head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As funções de expressão regulares auxiliam na tarefa de pré processamento.\n",
    "\n",
    "Alguns exemplos são encontrados aqui: https://stat.ethz.ch/R-manual/R-devel/library/base/html/regex.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_preprocessado <- movie_review$review %>% \n",
    "    gsub('[[:cntrl:]]', \"\", .) %>% # retira caracteres de controle\n",
    "    gsub(\"http\\\\S+\\\\s*\", \"\", .) %>% # retira caracteres relacionados ao html\n",
    "    gsub(\"\\\\d+\", \"\", .) %>% # retira caracteres numericos \n",
    "    gsub(\"[^[:graph:]]\", \" \", .) %>% # retira caracteres gráficos\n",
    "    str_replace_all(\"[^[:alnum:]]\", \" \") %>% # retira símbolos não alfanuméricos\n",
    "    str_replace_all(\"\\\\s+\", \" \") %>% # retira múltiplos espaços em branco\n",
    "    str_to_lower() # texto para minusculo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_preprocessado %>% \n",
    "    head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para que este processo não seja tão repetitivo, pode-se criar funções que podem chamadas quando necessário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessamento_texto <- function(texto) {\n",
    "  \n",
    "    texto %>% \n",
    "        gsub('[[:cntrl:]]', \"\", .) %>% # retira caracteres de controle\n",
    "        gsub(\"http\\\\S+\\\\s*\", \"\", .) %>% # retira caracteres relacionados ao html\n",
    "        gsub(\"\\\\d+\", \"\", .) %>% # retira caracteres numericos \n",
    "        gsub(\"[^[:graph:]]\", \" \", .) %>% # retira caracteres gráficos\n",
    "        str_replace_all(\"[^[:alnum:]]\", \" \") %>% # retira símbolos não alfanuméricos\n",
    "        str_replace_all(\"\\\\s+\", \" \") %>% # retira múltiplos espaços em branco\n",
    "        str_to_lower() # texto para minusculo\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabela de sinônimos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tabela de sinônimos é uma etapa importante, porém ela pode ser desenvolvida durante todo o projeto de análise de texto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta etapa ocorre a divisão do conjunto de caracteres em uma lista de termos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exemplo\n",
    "stringr::str_split( texto_preprocessado[1], \n",
    "                   pattern = stringr::boundary(\"word\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Também pode-se criar funções que podem chamadas quando necessário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessamento_token <- function( texto ) {\n",
    "  \n",
    "  stringr::str_split( texto, pattern = stringr::boundary(\"word\") )\n",
    "  \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de documentos e termos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste exemplo iremos criar uma matriz pelo método *Bag of Words* (TF-DF), dado que desejamos criar uma nuvem de palavras. Na etapa de desenvolver o modelo de sentimento serão apresentados os métodos *one hot encoding* e TF-IDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O processo de criar a matriz é muito oneroso computacionalmente, tanto de processamento quanto de memória. Desta forma, iremos utilizar algumas funções do pacote *text2vec* (http://text2vec.org) que otimiza este trabalho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criamos uma função de iteração\n",
    "iterador <- itoken( movie_review$review, # textos\n",
    "                    preprocessor = preprocessamento_texto, # funcao de pre processamento\n",
    "                    tokenizer = preprocessamento_token, # divisao dos termos\n",
    "                    ids = movie_review$id, # id do texto\n",
    "                    progressbar = FALSE )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A matriz precisa ser construída a partir de um vocabulário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulario <- create_vocabulary( it = iterador, \n",
    "                                  ngram = c(1, 1), # combinacao de palavras\n",
    "                                  stopwords = stopwords(\"english\") # palavras comuns que podem ser desconsideradas \n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords\n",
    "stopwords(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como pode ser visto, muitos termos não fazem sentido estar nas análises. Portanto, torna-se importante podar o vocabulário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulario <- prune_vocabulary( vocabulario, \n",
    "                                 term_count_min = 10,  \n",
    "                                 doc_proportion_min = 0.05, \n",
    "                                 doc_proportion_max = 0.9 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Também é observados termos com somente uma ou duas letras/símbolos. Desta forma, também é importante ajustar estas ocorrências."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulario %<>% \n",
    "    filter( nchar(term) >= 4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após estas etapas, a matriz de termos pode ser construída."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_term_matrix <- create_dtm( iterador, \n",
    "                                    vocab_vectorizer( vocabulario ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim(document_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_term_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando-se o vocabulário criado anteriormente, podemos criar a nuvem de palavras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50 termos mais frequentes\n",
    "vocabulario %>% \n",
    "    arrange( desc(term_count) )  %>% \n",
    "    head( 50 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud( words = vocabulario$term, \n",
    "           freq = vocabulario$term_count, \n",
    "           max.words =  50,\n",
    "           colors = c(\"blue\",\"red\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise de sentimentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma forma de realilzar uma análise de sentimentos é aplicar um *Machine Learning* supervisionado utilizando a matriz de documentos e termos. No caso do nosso exemplo *movie reviews*, podemos aplicar um modelo de regressão logística, uma vez que a classificação é binária ( 1 - positivo, 0 - negativo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_review %>% \n",
    "    count( sentiment )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vimos anteriormente que a matriz de documentos e termos foi construída utilizando o método *Bag of words* e armazenada no objeto *document_term_matrix*. Iremos criar outras duas matrizes utilizando os métodos *one hot enconding* e TF-IDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TF-IDF: *Inverse Document Frequency*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gera o método de transformação TF-IDF\n",
    "tfidf = TfIdf$new()\n",
    "# transforma a matriz\n",
    "document_term_matrix_idf <- fit_transform(document_term_matrix, tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_term_matrix_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *One hot encoding*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforma a matriz\n",
    "document_term_matrix_onehot <- (document_term_matrix > 0) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_term_matrix_onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após definirmos as matrizes, podemos aplicar os modelos de regressão logística. Como são muitos termos, não é recomendado verificar os coeficientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_onehot <- glmnet( y = movie_review$sentiment, \n",
    "       x = document_term_matrix_onehot, \n",
    "       family = 'binomial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tfidf <- glmnet( y = movie_review$sentiment, \n",
    "       x = document_term_matrix_idf, \n",
    "       family = 'binomial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bagwords <- glmnet( y = movie_review$sentiment, \n",
    "       x = document_term_matrix, \n",
    "       family = 'binomial')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Podemos avaliar os modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_model_onehot <- predict( model_onehot, s=0.01, document_term_matrix_onehot, type = 'response' )\n",
    "pred_model_tfidf <- predict( model_tfidf, s=0.01, document_term_matrix_idf, type = 'response')\n",
    "pred_model_bagwords <- predict( model_bagwords, s=0.01, document_term_matrix, type = 'response')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metodo onehot\n",
    "InformationValue::confusionMatrix( movie_review$sentiment, \n",
    "                                   pred_model_onehot,\n",
    "                                   threshold = 0.5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metodo tf-idf\n",
    "InformationValue::confusionMatrix( movie_review$sentiment, \n",
    "                                   pred_model_tfidf,\n",
    "                                   threshold = 0.5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metodo bag of words\n",
    "InformationValue::confusionMatrix( movie_review$sentiment, \n",
    "                                   pred_model_bagwords,\n",
    "                                   threshold = 0.5 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "usando o pacote caret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_model_onehot_bin <- as.factor(ifelse( pred_model_onehot > 0.5, 1, 0 ))\n",
    "pred_model_tfidf_bin <- as.factor(ifelse( pred_model_tfidf > 0.5, 1, 0 ))\n",
    "pred_model_bagwords_bin <- as.factor(ifelse( pred_model_bagwords > 0.5, 1, 0 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caret::confusionMatrix( as.factor(movie_review$sentiment),\n",
    "                        pred_model_onehot_bin,\n",
    "                        positive = '1' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caret::confusionMatrix( as.factor(movie_review$sentiment),\n",
    "                        pred_model_tfidf_bin,\n",
    "                        positive = '1' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caret::confusionMatrix( as.factor(movie_review$sentiment),\n",
    "                        pred_model_bagwords_bin,\n",
    "                        positive = '1' )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
